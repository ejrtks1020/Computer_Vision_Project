{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cassava-leaf-disease-classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Kaggle-competition/blob/main/cassava_leaf_disease_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/cassava-leaf-disease-classification/train_images'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-01-13T12:30:58.435974Z",
          "iopub.execute_input": "2022-01-13T12:30:58.436254Z",
          "iopub.status.idle": "2022-01-13T12:31:06.53756Z",
          "shell.execute_reply.started": "2022-01-13T12:30:58.436224Z",
          "shell.execute_reply": "2022-01-13T12:31:06.53683Z"
        },
        "scrolled": true,
        "trusted": true,
        "id": "gncqlO8i55Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.539037Z",
          "iopub.execute_input": "2022-01-13T12:31:06.539464Z",
          "iopub.status.idle": "2022-01-13T12:31:06.566406Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.539422Z",
          "shell.execute_reply": "2022-01-13T12:31:06.565703Z"
        },
        "trusted": true,
        "id": "fmR99WU655Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.567634Z",
          "iopub.execute_input": "2022-01-13T12:31:06.568039Z",
          "iopub.status.idle": "2022-01-13T12:31:06.584Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.568Z",
          "shell.execute_reply": "2022-01-13T12:31:06.583217Z"
        },
        "trusted": true,
        "id": "1RM-i2cK55Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.585396Z",
          "iopub.execute_input": "2022-01-13T12:31:06.58565Z",
          "iopub.status.idle": "2022-01-13T12:31:06.594219Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.585616Z",
          "shell.execute_reply": "2022-01-13T12:31:06.593501Z"
        },
        "trusted": true,
        "id": "eHFIC9cw55Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.596856Z",
          "iopub.execute_input": "2022-01-13T12:31:06.5971Z",
          "iopub.status.idle": "2022-01-13T12:31:06.604681Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.597067Z",
          "shell.execute_reply": "2022-01-13T12:31:06.603821Z"
        },
        "trusted": true,
        "id": "7R8Qxd_M55Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['path'] = '/kaggle/input/cassava-leaf-disease-classification/train_images/' + df['image_id']\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.606035Z",
          "iopub.execute_input": "2022-01-13T12:31:06.606881Z",
          "iopub.status.idle": "2022-01-13T12:31:06.624793Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.606845Z",
          "shell.execute_reply": "2022-01-13T12:31:06.624075Z"
        },
        "trusted": true,
        "id": "bUKu6ji-55Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['path'].iloc[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.626001Z",
          "iopub.execute_input": "2022-01-13T12:31:06.626367Z",
          "iopub.status.idle": "2022-01-13T12:31:06.63445Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.626331Z",
          "shell.execute_reply": "2022-01-13T12:31:06.633629Z"
        },
        "trusted": true,
        "id": "9LypKLFC55Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.635731Z",
          "iopub.execute_input": "2022-01-13T12:31:06.636107Z",
          "iopub.status.idle": "2022-01-13T12:31:06.647639Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.636068Z",
          "shell.execute_reply": "2022-01-13T12:31:06.646803Z"
        },
        "trusted": true,
        "id": "gJJ_C2dm55Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline \n",
        "\n",
        "def show_grid_images(image_path_list, ncols=8, augmentor=None, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(title)\n",
        "        \n",
        "img_list_0 = df[df['label'] == 0]['path'].iloc[:4].to_list()\n",
        "img_list_1 = df[df['label'] == 1]['path'].iloc[:4].to_list()\n",
        "img_list_2 = df[df['label'] == 2]['path'].iloc[:4].to_list()\n",
        "img_list_3 = df[df['label'] == 3]['path'].iloc[:4].to_list()\n",
        "img_list_4 = df[df['label'] == 4]['path'].iloc[:4].to_list()\n",
        "\n",
        "show_grid_images(img_list_0, ncols = 4, title = '0')\n",
        "show_grid_images(img_list_1, ncols = 4, title = '1')\n",
        "show_grid_images(img_list_2, ncols = 4, title = '2')\n",
        "show_grid_images(img_list_3, ncols = 4, title = '3')\n",
        "show_grid_images(img_list_4, ncols = 4, title = '4')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:06.648907Z",
          "iopub.execute_input": "2022-01-13T12:31:06.649237Z",
          "iopub.status.idle": "2022-01-13T12:31:11.988729Z",
          "shell.execute_reply.started": "2022-01-13T12:31:06.649202Z",
          "shell.execute_reply": "2022-01-13T12:31:11.98801Z"
        },
        "trusted": true,
        "id": "EjDe6h8T55Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(img_list_4[0])\n",
        "image.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:11.990095Z",
          "iopub.execute_input": "2022-01-13T12:31:11.990639Z",
          "iopub.status.idle": "2022-01-13T12:31:12.006281Z",
          "shell.execute_reply.started": "2022-01-13T12:31:11.990598Z",
          "shell.execute_reply": "2022-01-13T12:31:12.00569Z"
        },
        "trusted": true,
        "id": "Ju9zRZwI55Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.007534Z",
          "iopub.execute_input": "2022-01-13T12:31:12.008201Z",
          "iopub.status.idle": "2022-01-13T12:31:12.018826Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.008164Z",
          "shell.execute_reply": "2022-01-13T12:31:12.018128Z"
        },
        "trusted": true,
        "id": "hqv9rYMR55Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.020205Z",
          "iopub.execute_input": "2022-01-13T12:31:12.020957Z",
          "iopub.status.idle": "2022-01-13T12:31:12.043997Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.020919Z",
          "shell.execute_reply": "2022-01-13T12:31:12.043297Z"
        },
        "trusted": true,
        "id": "TzEKP8xG55Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].map(lambda x: str(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.045212Z",
          "iopub.execute_input": "2022-01-13T12:31:12.045665Z",
          "iopub.status.idle": "2022-01-13T12:31:12.178872Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.045627Z",
          "shell.execute_reply": "2022-01-13T12:31:12.178191Z"
        },
        "trusted": true,
        "id": "u52fwLLD55Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map(lambda x: str(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.182212Z",
          "iopub.execute_input": "2022-01-13T12:31:12.182413Z",
          "iopub.status.idle": "2022-01-13T12:31:12.194919Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.182389Z",
          "shell.execute_reply": "2022-01-13T12:31:12.194264Z"
        },
        "trusted": true,
        "id": "xW-Gqb9u55Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.196289Z",
          "iopub.execute_input": "2022-01-13T12:31:12.196692Z",
          "iopub.status.idle": "2022-01-13T12:31:12.207088Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.196655Z",
          "shell.execute_reply": "2022-01-13T12:31:12.205676Z"
        },
        "trusted": true,
        "id": "YV-B6deS55Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# scikit learn의 train_test_split()을 이용하여 train용, validation용 DataFrame을 생성\n",
        "# stratify를 이용하여 label 값을 균등하게 분할 \n",
        "tr_df, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=2022)\n",
        "print('tr_df shape:', tr_df.shape, 'val_df shape:', val_df.shape)\n",
        "print('tr_df label distribution:\\n', tr_df['label'].value_counts())\n",
        "print('val_df label distributuion:\\n', val_df['label'].value_counts())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.208528Z",
          "iopub.execute_input": "2022-01-13T12:31:12.208709Z",
          "iopub.status.idle": "2022-01-13T12:31:12.974564Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.208687Z",
          "shell.execute_reply": "2022-01-13T12:31:12.973834Z"
        },
        "trusted": true,
        "id": "WHNd1VEq55Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "### Preprocessing과 Data Loading을 동시에 적용. 단 실제 Preprocessing과 Data Loading을 Model에서 fit_generator()를 호출하기 전까지는 동작하지 않음. \n",
        "# augmentation은 horizontal_flip(좌우 반전)만 적용하고 0 ~ 255의 pixel값을 0 ~ 1 로 scale만 적용. \n",
        "train_gen = ImageDataGenerator(horizontal_flip=True, rescale=1/255.)\n",
        "\n",
        "# ImageDataGenerator 객체의 flow_from_directory() 메소드를 호출. \n",
        "# class_mode='categorical' 로 Label 데이터를 원-핫 인코딩, 이미지 array는 224 x 224 로 변경. Batch 크기는 64로 설정. \n",
        "train_flow_gen = train_gen.flow_from_dataframe(dataframe=tr_df # image file이 있는 디렉토리\n",
        "                                      ,x_col='path'\n",
        "                                      ,y_col='label'\n",
        "                                      ,target_size=(224, 224) # 원본 이미지를 최종 resize할 image size\n",
        "                                      ,class_mode='categorical' # 문자열 label을 자동 Encoding. \n",
        "                                      ,batch_size=32\n",
        "                                      ,shuffle=True\n",
        "                                      )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:12.97569Z",
          "iopub.execute_input": "2022-01-13T12:31:12.975926Z",
          "iopub.status.idle": "2022-01-13T12:31:23.469467Z",
          "shell.execute_reply.started": "2022-01-13T12:31:12.975892Z",
          "shell.execute_reply": "2022-01-13T12:31:23.468714Z"
        },
        "trusted": true,
        "id": "dD09rxMf55Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "val_gen = ImageDataGenerator(rescale = 1/255.)\n",
        "val_flow_gen = val_gen.flow_from_dataframe(val_df,\n",
        "                                          x_col = 'path',\n",
        "                                          y_col = 'label',\n",
        "                                          target_size = (224, 224),\n",
        "                                          class_model = 'categorical',\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:23.470679Z",
          "iopub.execute_input": "2022-01-13T12:31:23.471625Z",
          "iopub.status.idle": "2022-01-13T12:31:24.682678Z",
          "shell.execute_reply.started": "2022-01-13T12:31:23.471584Z",
          "shell.execute_reply": "2022-01-13T12:31:24.681906Z"
        },
        "trusted": true,
        "id": "S4Up2nX655Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_model(model_type='efficientnetb0', in_shape=(224, 224, 3), n_classes=5):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb2':\n",
        "        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb3':\n",
        "        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb4':\n",
        "        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb5':\n",
        "        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb6':\n",
        "        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb7':\n",
        "        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:24.684004Z",
          "iopub.execute_input": "2022-01-13T12:31:24.684615Z",
          "iopub.status.idle": "2022-01-13T12:31:24.710298Z",
          "shell.execute_reply.started": "2022-01-13T12:31:24.684579Z",
          "shell.execute_reply": "2022-01-13T12:31:24.709514Z"
        },
        "trusted": true,
        "id": "MxjCP5eH55Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xception = create_model(model_type='xception')\n",
        "# 최종 output 출력을 softmax에서 sigmoid로 변환되었으므로 binary_crossentropy로 변환 \n",
        "model_xception.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "# 5번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:24.711655Z",
          "iopub.execute_input": "2022-01-13T12:31:24.712175Z",
          "iopub.status.idle": "2022-01-13T12:31:28.589766Z",
          "shell.execute_reply.started": "2022-01-13T12:31:24.712122Z",
          "shell.execute_reply": "2022-01-13T12:31:28.589054Z"
        },
        "trusted": true,
        "id": "Jl37FXhz55Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epochs = 15\n",
        "#model_xception.fit(train_flow_gen, epochs = epochs,\n",
        "#         steps_per_epoch = int(np.ceil(tr_df.shape[0]/32)),\n",
        "#         validation_data = val_flow_gen,\n",
        "#         validation_steps= int(np.ceil(val_df.shape[0]/32)),\n",
        "#         callbacks = [rlr_cb, ely_cb])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:28.591195Z",
          "iopub.execute_input": "2022-01-13T12:31:28.591475Z",
          "iopub.status.idle": "2022-01-13T12:31:28.594372Z",
          "shell.execute_reply.started": "2022-01-13T12:31:28.591438Z",
          "shell.execute_reply": "2022-01-13T12:31:28.593731Z"
        },
        "trusted": true,
        "id": "CN-j2kRU55Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread('../input/cassava-leaf-disease-classification/test_images/2216849948.jpg')\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "test_img = cv2.resize(test_img, (224, 224))\n",
        "test_img = np.expand_dims(test_img, axis = 0)\n",
        "test_pred = model_xception.predict(test_img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:28.595556Z",
          "iopub.execute_input": "2022-01-13T12:31:28.595938Z",
          "iopub.status.idle": "2022-01-13T12:31:35.097802Z",
          "shell.execute_reply.started": "2022-01-13T12:31:28.595903Z",
          "shell.execute_reply": "2022-01-13T12:31:35.097003Z"
        },
        "trusted": true,
        "id": "jnr8ysxS55Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(test_pred, axis = 1)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:35.100295Z",
          "iopub.execute_input": "2022-01-13T12:31:35.100793Z",
          "iopub.status.idle": "2022-01-13T12:31:35.107275Z",
          "shell.execute_reply.started": "2022-01-13T12:31:35.100755Z",
          "shell.execute_reply": "2022-01-13T12:31:35.106213Z"
        },
        "trusted": true,
        "id": "hFjaOVK055Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. image size는 (높이, 너비)로 수정. \n",
        "class Plant_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=(224, 224), batch_size=64, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        # index는 몇번째 batch인지를 나타냄. \n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # label_batch가 None이 될 수 있음. \n",
        "        else: \n",
        "            label_batch = None\n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size[0], self.image_size[1], 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            #원본 이미지와 다르게 resize 적용. opencv의 resize은 (가로, 세로)의 개념임. 배열은 (높이, 너비)의 개념이므로 이에 주의하여 opencv resize 인자 입력 필요.  \n",
        "            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n",
        "            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:35.109083Z",
          "iopub.execute_input": "2022-01-13T12:31:35.109395Z",
          "iopub.status.idle": "2022-01-13T12:31:35.125959Z",
          "shell.execute_reply.started": "2022-01-13T12:31:35.109336Z",
          "shell.execute_reply": "2022-01-13T12:31:35.125207Z"
        },
        "trusted": true,
        "id": "skv_rbr755Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid(train_df, valid_size = 0.2):\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.get_dummies(train_df['label']).values\n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size = valid_size)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:35.12745Z",
          "iopub.execute_input": "2022-01-13T12:31:35.127761Z",
          "iopub.status.idle": "2022-01-13T12:31:35.138669Z",
          "shell.execute_reply.started": "2022-01-13T12:31:35.127726Z",
          "shell.execute_reply": "2022-01-13T12:31:35.137914Z"
        },
        "trusted": true,
        "id": "fDQD8gge55Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df['label']).values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:35.139693Z",
          "iopub.execute_input": "2022-01-13T12:31:35.139878Z",
          "iopub.status.idle": "2022-01-13T12:31:35.153123Z",
          "shell.execute_reply.started": "2022-01-13T12:31:35.139857Z",
          "shell.execute_reply": "2022-01-13T12:31:35.152247Z"
        },
        "trusted": true,
        "id": "1scTrzBc55Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "import albumentations as A\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. \n",
        "def lrfn_01(epoch):\n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "def lrfn_02(epoch):\n",
        "    LR_START = 1e-6\n",
        "    LR_MAX = 2e-5\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "lr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\n",
        "lr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\n",
        "rlr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "# Augmentor 생성. \n",
        "augmentor_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
        "    A.Blur(p=0.2)\n",
        "])\n",
        "\n",
        "# Config 생성. \n",
        "class Config:\n",
        "    MODEL_TYPE = 'xception'\n",
        "    IMAGE_SIZE = (224, 224)\n",
        "    BATCH_SIZE = 32\n",
        "    N_EPOCHS = 15 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_01\n",
        "    PRE_FUNC = xcp_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:35.154796Z",
          "iopub.execute_input": "2022-01-13T12:31:35.155141Z",
          "iopub.status.idle": "2022-01-13T12:31:36.459786Z",
          "shell.execute_reply.started": "2022-01-13T12:31:35.155107Z",
          "shell.execute_reply": "2022-01-13T12:31:36.459053Z"
        },
        "trusted": true,
        "id": "JJ9tJLDo55Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_df, config=Config):\n",
        "    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2)\n",
        "    tr_ds = Plant_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n",
        "    val_ds = Plant_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    if config.DEBUG:\n",
        "        tr_image_batch = next(iter(tr_ds))[0]\n",
        "        val_image_batch = next(iter(val_ds))[0]\n",
        "        \n",
        "        print(tr_image_batch.shape, val_image_batch.shape)\n",
        "        print(tr_image_batch[0], val_image_batch[0])\n",
        "        \n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=5)\n",
        "    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # 만일 Fine tuning 일 경우 아래 로직 적용. \n",
        "    if config.IS_FINE_TUNING:\n",
        "        print('####### Fine tuning 학습을 시작합니다. ########')\n",
        "        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n",
        "        for layer in model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        print('####### Classification Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외. \n",
        "        for layer in model.layers:\n",
        "            if config.MODEL_TYPE in 'efficientnet':\n",
        "                if not isinstance(layer, layers.BatchNormalization):\n",
        "                    layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n",
        "    \n",
        "    # Fine Tuning이 아닐 경우 \n",
        "    else:\n",
        "        print('####### 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "    return model, history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:36.462276Z",
          "iopub.execute_input": "2022-01-13T12:31:36.462698Z",
          "iopub.status.idle": "2022-01-13T12:31:36.478407Z",
          "shell.execute_reply.started": "2022-01-13T12:31:36.46266Z",
          "shell.execute_reply": "2022-01-13T12:31:36.477323Z"
        },
        "trusted": true,
        "id": "E0w02ukM55Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xcp_model, history = train_model(df, config=Config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T12:31:36.480508Z",
          "iopub.execute_input": "2022-01-13T12:31:36.480827Z",
          "iopub.status.idle": "2022-01-13T13:49:37.666713Z",
          "shell.execute_reply.started": "2022-01-13T12:31:36.48079Z",
          "shell.execute_reply": "2022-01-13T13:49:37.66597Z"
        },
        "trusted": true,
        "id": "19tCYPmb55Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "ids = []\n",
        "paths = []\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/cassava-leaf-disease-classification/test_images'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "        paths.append(os.path.join(dirname, filename))\n",
        "        ids.append(filename)\n",
        "\n",
        "test_df = pd.DataFrame({'id':ids, 'path':paths})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T13:49:37.669025Z",
          "iopub.execute_input": "2022-01-13T13:49:37.669454Z",
          "iopub.status.idle": "2022-01-13T13:49:37.682573Z",
          "shell.execute_reply.started": "2022-01-13T13:49:37.669414Z",
          "shell.execute_reply": "2022-01-13T13:49:37.681812Z"
        },
        "trusted": true,
        "id": "oEQ6pbJ_55Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T13:49:37.685338Z",
          "iopub.execute_input": "2022-01-13T13:49:37.685535Z",
          "iopub.status.idle": "2022-01-13T13:49:37.69654Z",
          "shell.execute_reply.started": "2022-01-13T13:49:37.685511Z",
          "shell.execute_reply": "2022-01-13T13:49:37.69583Z"
        },
        "trusted": true,
        "id": "A-gfT3Zx55Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_submit_df(test_df, model, config=Config):\n",
        "    test_path = '/kaggle/input/cassava-leaf-disease-classification/test_images/' + test_df['image_id'].values\n",
        "    # labels는 None을 입력하고 Dataset 생성. \n",
        "    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                            augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    #predict()로 예측 수행. \n",
        "    preds = model.predict(test_ds)\n",
        "    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성.\n",
        "    test_df['label'] = np.argmax(preds, axis = 1)\n",
        "    #submit_df = pd.DataFrame({'image_id':test_df['id'], 'label':np.argmax(preds, axis = 1)})\n",
        "    \n",
        "    return test_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T14:26:09.462856Z",
          "iopub.execute_input": "2022-01-13T14:26:09.463174Z",
          "iopub.status.idle": "2022-01-13T14:26:09.469925Z",
          "shell.execute_reply.started": "2022-01-13T14:26:09.463122Z",
          "shell.execute_reply": "2022-01-13T14:26:09.468804Z"
        },
        "trusted": true,
        "id": "BcPUwnf655Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_leaf = \"../input/cassava-leaf-disease-classification/test_images\"\n",
        "\n",
        "test_df= pd.DataFrame({'image_id':os.listdir(test_leaf)})\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T14:24:04.031854Z",
          "iopub.execute_input": "2022-01-13T14:24:04.032468Z",
          "iopub.status.idle": "2022-01-13T14:24:04.039785Z",
          "shell.execute_reply.started": "2022-01-13T14:24:04.032415Z",
          "shell.execute_reply": "2022-01-13T14:24:04.03903Z"
        },
        "trusted": true,
        "id": "Insu7vvg55Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T14:24:11.527911Z",
          "iopub.execute_input": "2022-01-13T14:24:11.528184Z",
          "iopub.status.idle": "2022-01-13T14:24:11.537215Z",
          "shell.execute_reply.started": "2022-01-13T14:24:11.528134Z",
          "shell.execute_reply": "2022-01-13T14:24:11.536278Z"
        },
        "trusted": true,
        "id": "A0qwQZLI55Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df = make_submit_df(test_df, xcp_model, config=Config)\n",
        "\n",
        "submit_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T14:26:23.443599Z",
          "iopub.execute_input": "2022-01-13T14:26:23.443855Z",
          "iopub.status.idle": "2022-01-13T14:26:23.529886Z",
          "shell.execute_reply.started": "2022-01-13T14:26:23.443827Z",
          "shell.execute_reply": "2022-01-13T14:26:23.529109Z"
        },
        "trusted": true,
        "id": "HhVEOnxt55Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T14:26:31.531228Z",
          "iopub.execute_input": "2022-01-13T14:26:31.531774Z",
          "iopub.status.idle": "2022-01-13T14:26:31.543401Z",
          "shell.execute_reply.started": "2022-01-13T14:26:31.531736Z",
          "shell.execute_reply": "2022-01-13T14:26:31.542728Z"
        },
        "trusted": true,
        "id": "2CrNH6MK55Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7_A9bH5c55Uy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}